{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#TextGAN for synthetic Text Generation \n",
        "\n"
      ],
      "metadata": {
        "id": "kiI8tBc57UJd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IOW0ohxKoEr9"
      },
      "outputs": [],
      "source": [
        "#reading the data\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('Twitter_Data.csv')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "owFdF5YFoGFQ",
        "outputId": "22bdcf60-6d9d-463f-c1f0-5087f00ab933"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               clean_text  category\n",
              "0       when modi promised “minimum government maximum...      -1.0\n",
              "1       talk all the nonsense and continue all the dra...       0.0\n",
              "2       what did just say vote for modi  welcome bjp t...       1.0\n",
              "3       asking his supporters prefix chowkidar their n...       1.0\n",
              "4       answer who among these the most powerful world...       1.0\n",
              "...                                                   ...       ...\n",
              "162975  why these 456 crores paid neerav modi not reco...      -1.0\n",
              "162976  dear rss terrorist payal gawar what about modi...      -1.0\n",
              "162977  did you cover her interaction forum where she ...       0.0\n",
              "162978  there big project came into india modi dream p...       0.0\n",
              "162979  have you ever listen about like gurukul where ...       1.0\n",
              "\n",
              "[162980 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-78f3e44d-c3ed-40d8-9c38-ac4b94ebf586\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean_text</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>when modi promised “minimum government maximum...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>talk all the nonsense and continue all the dra...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>asking his supporters prefix chowkidar their n...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>answer who among these the most powerful world...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162975</th>\n",
              "      <td>why these 456 crores paid neerav modi not reco...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162976</th>\n",
              "      <td>dear rss terrorist payal gawar what about modi...</td>\n",
              "      <td>-1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162977</th>\n",
              "      <td>did you cover her interaction forum where she ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162978</th>\n",
              "      <td>there big project came into india modi dream p...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162979</th>\n",
              "      <td>have you ever listen about like gurukul where ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>162980 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-78f3e44d-c3ed-40d8-9c38-ac4b94ebf586')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-78f3e44d-c3ed-40d8-9c38-ac4b94ebf586 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-78f3e44d-c3ed-40d8-9c38-ac4b94ebf586');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#verifying the number of samples for imbalance\n",
        "print(df['category'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLU0TD82oGJY",
        "outputId": "c24ddb3d-1eb2-4d07-f797-f72ae7ff0674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 1.0    13569\n",
            " 0.0    10942\n",
            "-1.0     7492\n",
            "Name: category, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"clean_text\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-EIY-eOqI6U",
        "outputId": "cf944fb3-ef43-47cf-c0af-fa29e2430351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        when modi promised “minimum government maximum...\n",
              "1        talk all the nonsense and continue all the dra...\n",
              "2        what did just say vote for modi  welcome bjp t...\n",
              "3        asking his supporters prefix chowkidar their n...\n",
              "4        answer who among these the most powerful world...\n",
              "                               ...                        \n",
              "31999      yup looks more like older version raga den modi\n",
              "32000    modi have punished lots corrupt but cant remember\n",
              "32001    religion peace agenda clear hai chahe padhe li...\n",
              "32002    chowkidar narendra modi was doing such stellar...\n",
              "32003    joshi should fielded joint opposition candidat...\n",
              "Name: clean_text, Length: 32004, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping nan values\n",
        "df = df.dropna(subset=['clean_text'])"
      ],
      "metadata": {
        "id": "bPRNavbrri1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data pre processing\n",
        "import re\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'http\\S+', '', text) # remove urls\n",
        "    text = re.sub(r'@[^\\s]+', '', text) # remove mentions\n",
        "    text = re.sub(r'#([^\\s]+)', r'\\1', text) # remove hashtags\n",
        "    return text.strip()\n",
        "\n",
        "df = df[['category', 'clean_text']]\n",
        "df['clean_text'] = df['clean_text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "f0GkrBMDoGLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "K8Cy42CioGPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qpa1HMbhrzhK",
        "outputId": "e75941c8-bba7-42ae-bf3b-aa22a2c287a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.27.4-py3-none-any.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.10.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.65.0)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.13.4-py3-none-any.whl (200 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.1/200.1 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.0.12)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.13.4 tokenizers-0.13.3 transformers-4.27.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# Define the device (CPU or GPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Initialize the tokenizer and the pre-trained BERT model\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "bert = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
        "\n",
        "# Define the maximum length of the input text and the batch size\n",
        "max_len = 128\n",
        "batch_size = 32\n",
        "\n",
        "# Define a custom dataset class\n",
        "class TwitterDataset(Dataset):\n",
        "    def __init__(self, df, max_len, tokenizer):\n",
        "        self.df = df\n",
        "        self.max_len = max_len\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        tweet = self.df.iloc[index]['clean_text']\n",
        "        label = self.df.iloc[index]['category']\n",
        "        \n",
        "        # Tokenize the tweet\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            tweet,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        \n",
        "        # Convert the label to an integer\n",
        "        if label == 'Positive':\n",
        "            label = 2\n",
        "        elif label == 'Negative':\n",
        "            label = 0\n",
        "        else:\n",
        "            label = 1\n",
        "            \n",
        "        input_ids = inputs['input_ids'].squeeze()\n",
        "        attention_mask = inputs['attention_mask'].squeeze()\n",
        "        token_type_ids = inputs['token_type_ids'].squeeze()\n",
        "\n",
        "        # Return a tuple containing the input_ids, attention_mask, token_type_ids, and label tensors\n",
        "        return input_ids, attention_mask, token_type_ids, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Create the dataloaders\n",
        "train_dataset = TwitterDataset(train_df, max_len=784, tokenizer=tokenizer)\n",
        "val_dataset = TwitterDataset(val_df, max_len=784, tokenizer=tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "# Define the generator model\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, latent_dim, output_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.fc1 = nn.Linear(self.latent_dim, 128)\n",
        "        self.fc2 = nn.Linear(128, 256)\n",
        "        self.fc3 = nn.Linear(256, 512)\n",
        "        self.fc4 = nn.Linear(512, self.output_dim)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.relu(self.fc3(x))\n",
        "        x = self.sigmoid(self.fc4(x))\n",
        "        return x\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.fc3 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.view(-1, 28*28)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdwzKc9yoQo4",
        "outputId": "37878db3-c335-43c7-f6a5-7a372ebd331f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(real_data['input_ids'].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ngwTGs4uRNT",
        "outputId": "b1ef863c-869d-43d9-b0a3-09bf1e7adb42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(fake_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dlnfnZSulaE",
        "outputId": "58aaa4be-f84d-4a7d-f2bd-fc70c34ba97d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 784])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rF1l99Pa6eEn",
        "outputId": "69bd4bfa-fd4e-4065-94bf-c850af913f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.1309e-06, 9.9975e-01, 1.0000e+00,  ..., 4.0488e-08, 2.9373e-07,\n",
              "         4.8612e-08],\n",
              "        [1.8430e-05, 9.9945e-01, 1.0000e+00,  ..., 2.7292e-07, 1.6756e-06,\n",
              "         3.0052e-07],\n",
              "        [1.4357e-06, 9.9988e-01, 1.0000e+00,  ..., 9.8435e-09, 8.3949e-08,\n",
              "         1.3186e-08],\n",
              "        ...,\n",
              "        [1.3064e-05, 9.9953e-01, 1.0000e+00,  ..., 1.5409e-07, 9.4969e-07,\n",
              "         1.8482e-07],\n",
              "        [6.6278e-06, 9.9966e-01, 1.0000e+00,  ..., 7.6031e-08, 4.9770e-07,\n",
              "         1.0738e-07],\n",
              "        [1.5767e-04, 9.9727e-01, 9.9995e-01,  ..., 5.6497e-06, 2.3490e-05,\n",
              "         7.4585e-06]], grad_fn=<SigmoidBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Define the generator and discriminator\n",
        "generator = Generator(latent_dim=100, output_dim=28*28).to(device)\n",
        "discriminator = Discriminator(input_dim=28*28, hidden_dim=256, output_dim=1).to(device)\n",
        "\n",
        "# Define the loss function and optimizer for the discriminator\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "d_optimizer = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Define the loss function and optimizer for the generator\n",
        "g_optimizer = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
        "\n",
        "# Define the number of epochs to train for\n",
        "num_epochs = 1\n",
        "\n",
        "# Loop over the epochs\n",
        "for epoch in range(num_epochs):\n",
        "    # Loop over the batches in the data loader\n",
        "    \n",
        "    for batch_idx, (input_ids, attention_mask, token_type_ids, labels) in enumerate(train_dataloader):\n",
        "        # Move the data to the device (CPU or GPU)\n",
        "        input_ids = input_ids.to(device).float()  # Convert to float data type\n",
        "        attention_mask = attention_mask.to(device)\n",
        "        token_type_ids = token_type_ids.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        ##############################\n",
        "        # Train the discriminator\n",
        "        ##############################\n",
        "        \n",
        "        # Reset the gradients for the discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        \n",
        "        # Generate a batch of fake data\n",
        "        z = torch.randn(batch_size, 100).to(device)\n",
        "        fake_data = generator(z)\n",
        "        \n",
        "        # Get the discriminator's output for the real and fake data\n",
        "        # Get the discriminator's output for the real and fake data\n",
        "        d_real = discriminator(input_ids.view(-1, 28*28))\n",
        "        d_fake = discriminator(fake_data.detach().view(-1, 28*28))\n",
        "\n",
        "        \n",
        "        # Calculate the loss for the discriminator\n",
        "        d_real_loss = criterion(d_real, torch.ones_like(d_real))\n",
        "        d_fake_loss = criterion(d_fake, torch.zeros_like(d_fake))\n",
        "        d_loss = (d_real_loss + d_fake_loss) / 2\n",
        "        \n",
        "        # Backpropagate the gradients and update the weights for the discriminator\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "        \n",
        "        ##############################\n",
        "        # Train the generator\n",
        "        ##############################\n",
        "        \n",
        "        # Reset the gradients for the generator\n",
        "        g_optimizer.zero_grad()\n",
        "        \n",
        "        # Generate a new batch of fake data\n",
        "        z = torch.randn(batch_size, 100).to(device)\n",
        "        fake_data = generator(z)\n",
        "        \n",
        "        # Get the discriminator's output for the fake data\n",
        "        d_fake = discriminator(fake_data.view(-1, 28*28))\n",
        "        \n",
        "        # Calculate the loss for the generator\n",
        "        g_loss = criterion(d_fake, torch.ones_like(d_fake))\n",
        "        \n",
        "        # Backpropagate the gradients and update the weights for the generator\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "        \n",
        "        # Print out some statistics every few batches\n",
        "        if (batch_idx + 1) % 10 == 0:\n",
        "            print(f\"Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(train_dataloader)}], D_loss: {d_loss.item():.4f}, G_loss: {g_loss.item():.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyxiGwyqsWpg",
        "outputId": "564a1d42-b2b4-4d56-808b-ec6bd9b295cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/1], Batch [10/801], D_loss: 0.2418, G_loss: 0.9905\n",
            "Epoch [1/1], Batch [20/801], D_loss: 0.1998, G_loss: 1.1477\n",
            "Epoch [1/1], Batch [30/801], D_loss: 0.2738, G_loss: 0.8730\n",
            "Epoch [1/1], Batch [40/801], D_loss: 0.3044, G_loss: 0.7943\n",
            "Epoch [1/1], Batch [50/801], D_loss: 0.3187, G_loss: 0.7493\n",
            "Epoch [1/1], Batch [60/801], D_loss: 0.3280, G_loss: 0.7332\n",
            "Epoch [1/1], Batch [70/801], D_loss: 0.3285, G_loss: 0.7304\n",
            "Epoch [1/1], Batch [80/801], D_loss: 0.3338, G_loss: 0.7190\n",
            "Epoch [1/1], Batch [90/801], D_loss: 0.3317, G_loss: 0.7243\n",
            "Epoch [1/1], Batch [100/801], D_loss: 0.3288, G_loss: 0.7303\n",
            "Epoch [1/1], Batch [110/801], D_loss: 0.3278, G_loss: 0.7336\n",
            "Epoch [1/1], Batch [120/801], D_loss: 0.3273, G_loss: 0.7333\n",
            "Epoch [1/1], Batch [130/801], D_loss: 0.3240, G_loss: 0.7412\n",
            "Epoch [1/1], Batch [140/801], D_loss: 0.3218, G_loss: 0.7461\n",
            "Epoch [1/1], Batch [150/801], D_loss: 0.3199, G_loss: 0.7505\n",
            "Epoch [1/1], Batch [160/801], D_loss: 0.3169, G_loss: 0.7572\n",
            "Epoch [1/1], Batch [170/801], D_loss: 0.3131, G_loss: 0.7657\n",
            "Epoch [1/1], Batch [180/801], D_loss: 0.3103, G_loss: 0.7727\n",
            "Epoch [1/1], Batch [190/801], D_loss: 0.3065, G_loss: 0.7815\n",
            "Epoch [1/1], Batch [200/801], D_loss: 0.3039, G_loss: 0.7877\n",
            "Epoch [1/1], Batch [210/801], D_loss: 0.3018, G_loss: 0.7924\n",
            "Epoch [1/1], Batch [220/801], D_loss: 0.2983, G_loss: 0.8008\n",
            "Epoch [1/1], Batch [230/801], D_loss: 0.2950, G_loss: 0.8091\n",
            "Epoch [1/1], Batch [240/801], D_loss: 0.2913, G_loss: 0.8185\n",
            "Epoch [1/1], Batch [250/801], D_loss: 0.2878, G_loss: 0.8274\n",
            "Epoch [1/1], Batch [260/801], D_loss: 0.2843, G_loss: 0.8364\n",
            "Epoch [1/1], Batch [270/801], D_loss: 0.2808, G_loss: 0.8457\n",
            "Epoch [1/1], Batch [280/801], D_loss: 0.2773, G_loss: 0.8549\n",
            "Epoch [1/1], Batch [290/801], D_loss: 0.2739, G_loss: 0.8642\n",
            "Epoch [1/1], Batch [300/801], D_loss: 0.2742, G_loss: 0.8633\n",
            "Epoch [1/1], Batch [310/801], D_loss: 0.2709, G_loss: 0.8722\n",
            "Epoch [1/1], Batch [320/801], D_loss: 0.2685, G_loss: 0.8795\n",
            "Epoch [1/1], Batch [330/801], D_loss: 0.2658, G_loss: 0.8868\n",
            "Epoch [1/1], Batch [340/801], D_loss: 0.2745, G_loss: 0.8626\n",
            "Epoch [1/1], Batch [350/801], D_loss: 0.2712, G_loss: 0.8716\n",
            "Epoch [1/1], Batch [360/801], D_loss: 0.2683, G_loss: 0.8797\n",
            "Epoch [1/1], Batch [370/801], D_loss: 0.2674, G_loss: 0.8820\n",
            "Epoch [1/1], Batch [380/801], D_loss: 0.2660, G_loss: 0.8863\n",
            "Epoch [1/1], Batch [390/801], D_loss: 0.2633, G_loss: 0.8942\n",
            "Epoch [1/1], Batch [400/801], D_loss: 0.2616, G_loss: 0.8990\n",
            "Epoch [1/1], Batch [410/801], D_loss: 0.2595, G_loss: 0.9051\n",
            "Epoch [1/1], Batch [420/801], D_loss: 0.2563, G_loss: 0.9147\n",
            "Epoch [1/1], Batch [430/801], D_loss: 0.2546, G_loss: 0.9196\n",
            "Epoch [1/1], Batch [440/801], D_loss: 0.2532, G_loss: 0.9241\n",
            "Epoch [1/1], Batch [450/801], D_loss: 0.2510, G_loss: 0.9307\n",
            "Epoch [1/1], Batch [460/801], D_loss: 0.2492, G_loss: 0.9364\n",
            "Epoch [1/1], Batch [470/801], D_loss: 0.2458, G_loss: 0.9468\n",
            "Epoch [1/1], Batch [480/801], D_loss: 0.2427, G_loss: 0.9567\n",
            "Epoch [1/1], Batch [490/801], D_loss: 0.2410, G_loss: 0.9624\n",
            "Epoch [1/1], Batch [500/801], D_loss: 0.2374, G_loss: 0.9742\n",
            "Epoch [1/1], Batch [510/801], D_loss: 0.2444, G_loss: 0.9327\n",
            "Epoch [1/1], Batch [520/801], D_loss: 0.2529, G_loss: 0.9251\n",
            "Epoch [1/1], Batch [530/801], D_loss: 0.2502, G_loss: 0.9333\n",
            "Epoch [1/1], Batch [540/801], D_loss: 0.2477, G_loss: 0.9411\n",
            "Epoch [1/1], Batch [550/801], D_loss: 0.2445, G_loss: 0.9511\n",
            "Epoch [1/1], Batch [560/801], D_loss: 0.2430, G_loss: 0.9560\n",
            "Epoch [1/1], Batch [570/801], D_loss: 0.2398, G_loss: 0.9660\n",
            "Epoch [1/1], Batch [580/801], D_loss: 0.2384, G_loss: 0.9705\n",
            "Epoch [1/1], Batch [590/801], D_loss: 0.2358, G_loss: 0.9792\n",
            "Epoch [1/1], Batch [600/801], D_loss: 0.2333, G_loss: 0.9874\n",
            "Epoch [1/1], Batch [610/801], D_loss: 0.2309, G_loss: 0.9954\n",
            "Epoch [1/1], Batch [620/801], D_loss: 0.2314, G_loss: 0.9938\n",
            "Epoch [1/1], Batch [630/801], D_loss: 0.2289, G_loss: 1.0022\n",
            "Epoch [1/1], Batch [640/801], D_loss: 0.2266, G_loss: 1.0101\n",
            "Epoch [1/1], Batch [650/801], D_loss: 0.2244, G_loss: 1.0180\n",
            "Epoch [1/1], Batch [660/801], D_loss: 0.2222, G_loss: 1.0258\n",
            "Epoch [1/1], Batch [670/801], D_loss: 0.2212, G_loss: 1.0295\n",
            "Epoch [1/1], Batch [680/801], D_loss: 0.2194, G_loss: 1.0359\n",
            "Epoch [1/1], Batch [690/801], D_loss: 0.2171, G_loss: 1.0442\n",
            "Epoch [1/1], Batch [700/801], D_loss: 0.2162, G_loss: 1.0479\n",
            "Epoch [1/1], Batch [710/801], D_loss: 0.2138, G_loss: 1.0566\n",
            "Epoch [1/1], Batch [720/801], D_loss: 0.2135, G_loss: 1.0576\n",
            "Epoch [1/1], Batch [730/801], D_loss: 0.2112, G_loss: 1.0664\n",
            "Epoch [1/1], Batch [740/801], D_loss: 0.2090, G_loss: 1.0749\n",
            "Epoch [1/1], Batch [750/801], D_loss: 0.2078, G_loss: 1.0795\n",
            "Epoch [1/1], Batch [760/801], D_loss: 0.2056, G_loss: 1.0880\n",
            "Epoch [1/1], Batch [770/801], D_loss: 0.2044, G_loss: 1.0931\n",
            "Epoch [1/1], Batch [780/801], D_loss: 0.2020, G_loss: 1.1027\n",
            "Epoch [1/1], Batch [790/801], D_loss: 0.1997, G_loss: 1.1120\n",
            "Epoch [1/1], Batch [800/801], D_loss: 0.1974, G_loss: 1.1210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the discriminator's output for the real data\n",
        "d_real = discriminator(input_ids.view(-1, 28*28))\n",
        "\n",
        "# Generate a batch of fake data\n",
        "z = torch.randn(batch_size, 100).to(device)\n",
        "fake_data = generator(z)\n",
        "\n",
        "# Get the discriminator's output for the fake data\n",
        "d_fake = discriminator(fake_data.detach().view(-1, 28*28))\n",
        "\n",
        "# Calculate the binary cross-entropy loss for the real and fake data\n",
        "loss_real = criterion(d_real, torch.ones_like(d_real))\n",
        "loss_fake = criterion(d_fake, torch.zeros_like(d_fake))\n",
        "\n",
        "# Compute the total loss as the sum of the losses for real and fake data\n",
        "total_loss = loss_real + loss_fake\n"
      ],
      "metadata": {
        "id": "obLdgpRL3Axh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_loss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y_Sdg0fB6Drx",
        "outputId": "7474e60b-8a07-4baa-a9fb-caaf45dbf2e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3940, grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    }
  ]
}